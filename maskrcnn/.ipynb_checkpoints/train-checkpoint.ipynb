{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "from pathlib import Path\n",
    "import skimage.io\n",
    "import tensorflow as tf\n",
    "\n",
    "# 获取项目根目录\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "sys.path.append(ROOT_DIR)\n",
    "# os.environ[\"TF_MIN_GPU_MULTIPROCESSOR_COUNT\"] = \"4\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "#基础配置路径\n",
    "settingsDir = os.path.join(ROOT_DIR,'settings.json')\n",
    "with open(settingsDir) as f:\n",
    "    setting = json.load(f)\n",
    "#获得当前路径\n",
    "ROOT_DIR = os.getcwd()\n",
    "sys.path.append(ROOT_DIR)\n",
    "DEFAULT_LOGS_DIR = os.path.join('../../', setting['LOGS_DIR'])\n",
    "\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils as utils\n",
    "from mrcnn import model as modellib\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "############################################################\n",
    "#  Configurations\n",
    "############################################################\n",
    "# 图像大小\n",
    "IMGSIZE = (1024, 1024)\n",
    "\n",
    "class AdrivingConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy  dataset.\n",
    "    Derives from the base Config class and overrides some values.\n",
    "    \"\"\"\n",
    "    #为这个配置命名。例如, 'COCO', 'Experiment 3', 等等。\n",
    "    NAME = \"Adriving\"\n",
    "    # We use a GPU with 12GB memory, which can fit two images.\n",
    "    # Adjust down if you use a smaller GPU.\n",
    "    GPU_COUNT = 1\n",
    "    #每个GPU一次处理多少幅图像。一个12GB的GPU\n",
    "    #可以处理两幅1024x1024px的图像.\n",
    "    #根据你的GPU显存和图像大小调整它.\n",
    "    #使用你的GPU最多能处理的数量可以获得最好的性能.\n",
    "    IMAGES_PER_GPU = 1\n",
    "    \n",
    "    #每个epoch训练的步数\n",
    "    #这个参数不需要匹配训练集的大小. Tensorboard\n",
    "    #Tensorboard的更新会在每个epoch的最后保存, so setting this to a\n",
    "    #所以将这个参数设的小一点，Tensorboard的更新频率更高.\n",
    "    #在每个epoch的最后也会更新验证的状态，这会花费一些时间\n",
    "    #所以不要把它设置的过小以避免浪费大量的时间在验证上\n",
    "    STEPS_PER_EPOCH = 10\n",
    "    #在每个训练epoch的结尾进行验证的步数.\n",
    "    #设置大一些可以提升验证的精度, 但是会减慢训练过程.\n",
    "    VALIDATION_STEPS = 1\n",
    "    \n",
    "    #分类数量(包括背景)\n",
    "    NUM_CLASSES = 1 + 7 \n",
    "    #图像均值(RGB)\n",
    "    MEAN_PIXEL = np.array([88.59672608, 95.91837699, 98.90089033])\n",
    "    \n",
    "    #Non-max suppression过滤RPN proposals时的阈值.\n",
    "    #在训练中增大它可以产生更多的propsals.\n",
    "    RPN_NMS_THRESHOLD = 0.6\n",
    "    TRAIN_ROIS_PER_IMAGE = 600\n",
    "    #每幅图像中使用多少anchors来训练RPN\n",
    "    RPN_TRAIN_ANCHORS_PER_IMAGE = 320\n",
    "    MAX_GT_INSTANCES = 80\n",
    "    \n",
    "    # non-maximum suppression之后保留多少ROIs(训练和预测)\n",
    "    POST_NMS_ROIS_TRAINING = 4000\n",
    "    POST_NMS_ROIS_INFERENCE = 2000\n",
    "    #检测时Non-maximum suppression的阈值\n",
    "    DETECTION_NMS_THRESHOLD = 0.3\n",
    "    #接受一个instance的最小可能性\n",
    "    #ROIs小于该值将被忽略\n",
    "    DETECTION_MIN_CONFIDENCE = 0.5\n",
    "    #最终检测的instances的最大数量\n",
    "    DETECTION_MAX_INSTANCES = 100\n",
    "    \n",
    "    #输入图像缩放\n",
    "    #通常, 训练和预测使用\"square\" 缩放模式，它在大部分情况下表现的很好\n",
    "    #在这个模式中, 缩放图像使其短边= IMAGE_MIN_DIM,但是也要确保长边\n",
    "    #不大于IMAGE_MAX_DIM. 可以对图像填充0使其成为正方形，\n",
    "    #这样多幅图像可以放在一个batch中\n",
    "    #可选的缩放模式:\n",
    "    # none:   无缩放或填充. 返回原图.\n",
    "    # square: 缩放或填充0，返回[max_dim, max_dim]大小的图像.\n",
    "    # pad64:  宽和高填充0，使他们成为64的倍数.\n",
    "    #         如果IMAGE_MIN_DIM 或 IMAGE_MIN_SCALE不为None, 则在填充之前先\n",
    "    #         缩放. IMAGE_MAX_DIM在该模式中被忽略.\n",
    "    #         要求为64的倍数是因为在对FPN金字塔的6个levels进行上/下采样时保证平滑(2**6=64).\n",
    "    # crop:   对图像进行随机裁剪. 首先, 基于IMAGE_MIN_DIM和IMAGE_MIN_SCALE\n",
    "    #         对图像进行缩放, 然后随机裁剪IMAGE_MIN_DIM x IMAGE_MIN_DIM大小. \n",
    "    #         仅在训练时使用.\n",
    "    IMAGE_MIN_DIM = IMGSIZE[0]\n",
    "    IMAGE_MAX_DIM = IMGSIZE[1]\n",
    "    IMAGE_RESIZE_MODE = \"none\"\n",
    "    #输出mask的形状\n",
    "    #更改这个参数需要同时修改neural network mask branch\n",
    "    MASK_SHAPE = [28, 28]\n",
    "    \n",
    "    OPTIMIZER = 'SGD'\n",
    "    LEARNING_RATE = 1e-6\n",
    "    EPSILON = 1e-6\n",
    "    GRADIENT_CLIP_NORM = 5\n",
    "    ACCUM_ITERS = 1\n",
    "\n",
    "############################################################\n",
    "#  Dataset\n",
    "############################################################\n",
    "from adriving_util import *\n",
    "\n",
    "def train(model):\n",
    "    \"\"\"Train the model.\"\"\"\n",
    "    # Training dataset.\n",
    "    \n",
    "    augmentation = iaa.SomeOf((0, 2), [\n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.Multiply((0.9, 1.1))\n",
    "        # iaa.GaussianBlur(sigma=(0.0, 1.0))\n",
    "    ])\n",
    "    \n",
    "    dataset_train = AdrivingDatasetNoResize()\n",
    "    dataset_train.load_adriving(data_dir, \"train\", size = IMGSIZE)\n",
    "    dataset_train.prepare()\n",
    "    print(len(dataset_train.image_ids))\n",
    "\n",
    "    # Validation dataset\n",
    "    dataset_val = AdrivingDatasetNoResize()\n",
    "    dataset_val.load_adriving(data_dir, \"val\", size = IMGSIZE)\n",
    "    dataset_val.prepare()\n",
    "\n",
    "    # *** This training schedule is an example. Update to your needs ***\n",
    "    # Since we're using a very small dataset, and starting from\n",
    "    # COCO trained weights, we don't need to train too long. Also,\n",
    "    # no need to train all layers, just the heads should do it.\n",
    "    print(\"Training network heads\")\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                augmentation=augmentation,\n",
    "                epochs=40,\n",
    "                layers='heads')\n",
    "    \n",
    "    model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            augmentation=augmentation,\n",
    "            epochs=50,\n",
    "            layers='4+')\n",
    "    \n",
    "    model.train(dataset_train, dataset_val,\n",
    "        learning_rate=config.LEARNING_RATE/10,\n",
    "        augmentation=augmentation,\n",
    "        epochs=100,\n",
    "        layers='3+')\n",
    "    \n",
    "    model.train(dataset_train, dataset_val,\n",
    "        learning_rate=config.LEARNING_RATE/10,\n",
    "        augmentation=augmentation,\n",
    "        epochs=100,\n",
    "        layers='all')\n",
    "    \n",
    "    \n",
    "# --------------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "ACCUM_ITERS                    1\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.5\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "EPSILON                        1e-06\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                20\n",
      "IMAGE_MIN_DIM                  1024\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              none\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  1e-06\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               80\n",
      "MEAN_PIXEL                     [88.59672608 95.91837699 98.90089033]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           Adriving\n",
      "NUM_CLASSES                    8\n",
      "OPTIMIZER                      SGD\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        2000\n",
      "POST_NMS_ROIS_TRAINING         4000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.6\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    320\n",
      "STEPS_PER_EPOCH                10\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           600\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               1\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系统找不到指定的路径。: 'C:\\\\Users\\\\Administrator\\\\Documents\\\\GitHub\\\\AiRobot_WAD_Video_Segmentation\\\\data\\\\train_val\\\\train\\\\image'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-1e7673388b54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mdata_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mROOT_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msetting\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TEST_DATA_CLEAN_PATH'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train_val'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-64d241eeaed7>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[0mdataset_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdrivingDatasetNoResize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m     \u001b[0mdataset_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_adriving\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIMGSIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m     \u001b[0mdataset_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\AiRobot_WAD_Video_Segmentation\\maskrcnn\\adriving_util.py\u001b[0m in \u001b[0;36mload_adriving\u001b[1;34m(self, dataset_dir, subset, size)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[0mtrain_image_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_dir\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;34m'image'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m         \u001b[0mcolor_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_image_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcolor_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'.'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 系统找不到指定的路径。: 'C:\\\\Users\\\\Administrator\\\\Documents\\\\GitHub\\\\AiRobot_WAD_Video_Segmentation\\\\data\\\\train_val\\\\train\\\\image'"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "#  Training\n",
    "############################################################\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    config = AdrivingConfig()\n",
    "    config.display()\n",
    "    DEVICE = \"/gpu:0\"  # /cpu:0 or /gpu:0\n",
    "\n",
    "    model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                              model_dir=os.path.join(DEFAULT_LOGS_DIR, 'mask_rcnn'))\n",
    "    \n",
    "    PRETRAIN_WEIGHTS_PATH = os.path.join(ROOT_DIR, setting['MODEL_CHECKPOINT_DIR'], 'pretrainmodel_maskrcnn.h5')\n",
    "\n",
    "    \n",
    "    weights_path = PRETRAIN_WEIGHTS_PATH\n",
    "    model.load_weights(weights_path, by_name=True)\n",
    "    \n",
    "    data_dir = Path(os.path.join(ROOT_DIR, setting['TEST_DATA_CLEAN_PATH'], 'train_val'))\n",
    "    train(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
