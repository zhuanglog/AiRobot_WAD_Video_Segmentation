{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H:\\ObjectDetection\\AiRobot_WAD_Video_Segmentation\\settings.json\n",
      "H:\\ObjectDetection\\AiRobot_WAD_Video_Segmentation\\logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "from pathlib import Path\n",
    "import skimage.io\n",
    "import tensorflow as tf\n",
    "\n",
    "# 获取项目根目录\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "sys.path.append(ROOT_DIR)\n",
    "# os.environ[\"TF_MIN_GPU_MULTIPROCESSOR_COUNT\"] = \"4\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "#基础配置路径\n",
    "settingsDir = os.path.join(ROOT_DIR,'settings.json')\n",
    "print (settingsDir)\n",
    "with open(settingsDir) as f:\n",
    "    setting = json.load(f)\n",
    "#获得当前路径\n",
    "ROOT_DIR = os.getcwd()\n",
    "sys.path.append(ROOT_DIR)\n",
    "DEFAULT_LOGS_DIR = Path(os.path.join(os.path.abspath(\"../\"),setting['LOGS_DIR']))\n",
    "print (DEFAULT_LOGS_DIR)\n",
    "\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils as utils\n",
    "from mrcnn import model as modellib\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "############################################################\n",
    "#  Configurations\n",
    "############################################################\n",
    "# 图像大小\n",
    "IMGSIZE = (1024, 1024)\n",
    "\n",
    "class AdrivingConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy  dataset.\n",
    "    Derives from the base Config class and overrides some values.\n",
    "    \"\"\"\n",
    "    #为这个配置命名。例如, 'COCO', 'Experiment 3', 等等。\n",
    "    NAME = \"Adriving\"\n",
    "    # We use a GPU with 12GB memory, which can fit two images.\n",
    "    # Adjust down if you use a smaller GPU.\n",
    "    GPU_COUNT = 1\n",
    "    #每个GPU一次处理多少幅图像。一个12GB的GPU\n",
    "    #可以处理两幅1024x1024px的图像.\n",
    "    #根据你的GPU显存和图像大小调整它.\n",
    "    #使用你的GPU最多能处理的数量可以获得最好的性能.\n",
    "    IMAGES_PER_GPU = 1\n",
    "    \n",
    "    #每个epoch训练的步数\n",
    "    #这个参数不需要匹配训练集的大小. Tensorboard\n",
    "    #Tensorboard的更新会在每个epoch的最后保存, so setting this to a\n",
    "    #所以将这个参数设的小一点，Tensorboard的更新频率更高.\n",
    "    #在每个epoch的最后也会更新验证的状态，这会花费一些时间\n",
    "    #所以不要把它设置的过小以避免浪费大量的时间在验证上\n",
    "    STEPS_PER_EPOCH = 666\n",
    "    #在每个训练epoch的结尾进行验证的步数.\n",
    "    #设置大一些可以提升验证的精度, 但是会减慢训练过程.\n",
    "    VALIDATION_STEPS = 66\n",
    "    \n",
    "    #分类数量(包括背景)\n",
    "    NUM_CLASSES = 1 + 7 \n",
    "    #图像均值(RGB)\n",
    "    MEAN_PIXEL = np.array([88.59672608, 95.91837699, 98.90089033])\n",
    "    \n",
    "    #Non-max suppression过滤RPN proposals时的阈值.\n",
    "    #在训练中增大它可以产生更多的propsals.\n",
    "    RPN_NMS_THRESHOLD = 0.6\n",
    "    TRAIN_ROIS_PER_IMAGE = 600\n",
    "    #每幅图像中使用多少anchors来训练RPN\n",
    "    RPN_TRAIN_ANCHORS_PER_IMAGE = 320\n",
    "    MAX_GT_INSTANCES = 80\n",
    "    \n",
    "    # non-maximum suppression之后保留多少ROIs(训练和预测)\n",
    "    POST_NMS_ROIS_TRAINING = 4000\n",
    "    POST_NMS_ROIS_INFERENCE = 2000\n",
    "    #检测时Non-maximum suppression的阈值\n",
    "    DETECTION_NMS_THRESHOLD = 0.3\n",
    "    #接受一个instance的最小可能性\n",
    "    #ROIs小于该值将被忽略\n",
    "    DETECTION_MIN_CONFIDENCE = 0.5\n",
    "    #最终检测的instances的最大数量\n",
    "    DETECTION_MAX_INSTANCES = 107\n",
    "    \n",
    "    #输入图像缩放\n",
    "    #通常, 训练和预测使用\"square\" 缩放模式，它在大部分情况下表现的很好\n",
    "    #在这个模式中, 缩放图像使其短边= IMAGE_MIN_DIM,但是也要确保长边\n",
    "    #不大于IMAGE_MAX_DIM. 可以对图像填充0使其成为正方形，\n",
    "    #这样多幅图像可以放在一个batch中\n",
    "    #可选的缩放模式:\n",
    "    # none:   无缩放或填充. 返回原图.\n",
    "    # square: 缩放或填充0，返回[max_dim, max_dim]大小的图像.\n",
    "    # pad64:  宽和高填充0，使他们成为64的倍数.\n",
    "    #         如果IMAGE_MIN_DIM 或 IMAGE_MIN_SCALE不为None, 则在填充之前先\n",
    "    #         缩放. IMAGE_MAX_DIM在该模式中被忽略.\n",
    "    #         要求为64的倍数是因为在对FPN金字塔的6个levels进行上/下采样时保证平滑(2**6=64).\n",
    "    # crop:   对图像进行随机裁剪. 首先, 基于IMAGE_MIN_DIM和IMAGE_MIN_SCALE\n",
    "    #         对图像进行缩放, 然后随机裁剪IMAGE_MIN_DIM x IMAGE_MIN_DIM大小. \n",
    "    #         仅在训练时使用.\n",
    "    IMAGE_MIN_DIM = IMGSIZE[0]\n",
    "    IMAGE_MAX_DIM = IMGSIZE[1]\n",
    "    IMAGE_RESIZE_MODE = \"none\"\n",
    "    #输出mask的形状\n",
    "    #更改这个参数需要同时修改neural network mask branch\n",
    "    MASK_SHAPE = [28, 28]\n",
    "    \n",
    "    OPTIMIZER = 'SGD'\n",
    "    LEARNING_RATE = 1e-6\n",
    "    EPSILON = 1e-6\n",
    "    GRADIENT_CLIP_NORM = 5\n",
    "    ACCUM_ITERS = 1\n",
    "\n",
    "############################################################\n",
    "#  Dataset\n",
    "############################################################\n",
    "from adriving_util import *\n",
    "\n",
    "def train(model):\n",
    "    \"\"\"Train the model.\"\"\"\n",
    "    # Training dataset.\n",
    "    \n",
    "    augmentation = iaa.SomeOf((0, 2), [\n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.Multiply((0.9, 1.1))\n",
    "        # iaa.GaussianBlur(sigma=(0.0, 1.0))\n",
    "    ])\n",
    "    \n",
    "    dataset_train = AdrivingDatasetNoResize()\n",
    "    dataset_train.load_adriving(data_dir, \"train\", size = IMGSIZE)\n",
    "    dataset_train.prepare()\n",
    "    print(len(dataset_train.image_ids))\n",
    "\n",
    "    # Validation dataset\n",
    "    dataset_val = AdrivingDatasetNoResize()\n",
    "    dataset_val.load_adriving(data_dir, \"val\", size = IMGSIZE)\n",
    "    dataset_val.prepare()\n",
    "\n",
    "    # *** This training schedule is an example. Update to your needs ***\n",
    "    # Since we're using a very small dataset, and starting from\n",
    "    # COCO trained weights, we don't need to train too long. Also,\n",
    "    # no need to train all layers, just the heads should do it.\n",
    "    print(\"Training network heads\")\n",
    "    # 通过传入参数layers=\"heads\" 冻结处理head部分的所有层。可以通过传入一个正则表达式选择要训练的层\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                augmentation=augmentation,\n",
    "                epochs=16,\n",
    "                layers='heads')\n",
    "    \n",
    "    model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            augmentation=augmentation,\n",
    "            epochs=32,\n",
    "            layers='4+')\n",
    "    \n",
    "    model.train(dataset_train, dataset_val,\n",
    "        learning_rate=config.LEARNING_RATE/10,\n",
    "        augmentation=augmentation,\n",
    "        epochs=48,\n",
    "        layers='3+')\n",
    "    # 通过传入参数layers=\"all\"所有层，Fine-tune所有层，上面训练了一会head部分，为了更好的适配新的数据集，需要fine-tune，使用layers='all'参数\n",
    "    model.train(dataset_train, dataset_val,\n",
    "        learning_rate=config.LEARNING_RATE/10,\n",
    "        augmentation=augmentation,\n",
    "        epochs=64,\n",
    "        layers='all')\n",
    "    \n",
    "    \n",
    "# --------------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "ACCUM_ITERS                    1\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        107\n",
      "DETECTION_MIN_CONFIDENCE       0.5\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "EPSILON                        1e-06\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                20\n",
      "IMAGE_MIN_DIM                  1024\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              none\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  1e-06\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               80\n",
      "MEAN_PIXEL                     [88.59672608 95.91837699 98.90089033]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           Adriving\n",
      "NUM_CLASSES                    8\n",
      "OPTIMIZER                      SGD\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        2000\n",
      "POST_NMS_ROIS_TRAINING         4000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.6\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    320\n",
      "STEPS_PER_EPOCH                666\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           600\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               66\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "35300\n",
      "Training network heads\n",
      "\n",
      "Starting at epoch 0. LR=1e-06\n",
      "\n",
      "Checkpoint Path: H:\\ObjectDetection\\AiRobot_WAD_Video_Segmentation\\logs\\mask_rcnn\\adriving20181030T0828\\mask_rcnn_adriving_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "666/666 [==============================] - 1574s 2s/step - loss: 0.6564 - rpn_class_loss: 0.0093 - rpn_bbox_loss: 0.2131 - mrcnn_class_loss: 0.0247 - mrcnn_bbox_loss: 0.1642 - mrcnn_mask_loss: 0.2450 - val_loss: 0.7065 - val_rpn_class_loss: 0.0096 - val_rpn_bbox_loss: 0.2614 - val_mrcnn_class_loss: 0.0253 - val_mrcnn_bbox_loss: 0.1694 - val_mrcnn_mask_loss: 0.2408\n",
      "Epoch 2/16\n",
      "666/666 [==============================] - 1549s 2s/step - loss: 0.6672 - rpn_class_loss: 0.0102 - rpn_bbox_loss: 0.2080 - mrcnn_class_loss: 0.0263 - mrcnn_bbox_loss: 0.1759 - mrcnn_mask_loss: 0.2467 - val_loss: 0.6553 - val_rpn_class_loss: 0.0089 - val_rpn_bbox_loss: 0.2434 - val_mrcnn_class_loss: 0.0256 - val_mrcnn_bbox_loss: 0.1509 - val_mrcnn_mask_loss: 0.2265\n",
      "Epoch 3/16\n",
      "666/666 [==============================] - 1534s 2s/step - loss: 0.6632 - rpn_class_loss: 0.0101 - rpn_bbox_loss: 0.2302 - mrcnn_class_loss: 0.0247 - mrcnn_bbox_loss: 0.1590 - mrcnn_mask_loss: 0.2390 - val_loss: 0.7189 - val_rpn_class_loss: 0.0097 - val_rpn_bbox_loss: 0.2258 - val_mrcnn_class_loss: 0.0276 - val_mrcnn_bbox_loss: 0.1956 - val_mrcnn_mask_loss: 0.2601\n",
      "Epoch 4/16\n",
      "666/666 [==============================] - 1567s 2s/step - loss: 0.6966 - rpn_class_loss: 0.0105 - rpn_bbox_loss: 0.2366 - mrcnn_class_loss: 0.0268 - mrcnn_bbox_loss: 0.1755 - mrcnn_mask_loss: 0.2472 - val_loss: 0.7165 - val_rpn_class_loss: 0.0085 - val_rpn_bbox_loss: 0.2718 - val_mrcnn_class_loss: 0.0233 - val_mrcnn_bbox_loss: 0.1809 - val_mrcnn_mask_loss: 0.2318\n",
      "Epoch 5/16\n",
      "666/666 [==============================] - 1546s 2s/step - loss: 0.6771 - rpn_class_loss: 0.0103 - rpn_bbox_loss: 0.2186 - mrcnn_class_loss: 0.0261 - mrcnn_bbox_loss: 0.1767 - mrcnn_mask_loss: 0.2453 - val_loss: 0.6384 - val_rpn_class_loss: 0.0080 - val_rpn_bbox_loss: 0.1869 - val_mrcnn_class_loss: 0.0271 - val_mrcnn_bbox_loss: 0.1674 - val_mrcnn_mask_loss: 0.2489\n",
      "Epoch 6/16\n",
      "666/666 [==============================] - 1574s 2s/step - loss: 0.6539 - rpn_class_loss: 0.0096 - rpn_bbox_loss: 0.2160 - mrcnn_class_loss: 0.0238 - mrcnn_bbox_loss: 0.1632 - mrcnn_mask_loss: 0.2412 - val_loss: 0.6475 - val_rpn_class_loss: 0.0092 - val_rpn_bbox_loss: 0.2115 - val_mrcnn_class_loss: 0.0232 - val_mrcnn_bbox_loss: 0.1626 - val_mrcnn_mask_loss: 0.2410\n",
      "Epoch 7/16\n",
      "666/666 [==============================] - 1563s 2s/step - loss: 0.6574 - rpn_class_loss: 0.0098 - rpn_bbox_loss: 0.2098 - mrcnn_class_loss: 0.0262 - mrcnn_bbox_loss: 0.1703 - mrcnn_mask_loss: 0.2412 - val_loss: 0.6563 - val_rpn_class_loss: 0.0081 - val_rpn_bbox_loss: 0.2321 - val_mrcnn_class_loss: 0.0236 - val_mrcnn_bbox_loss: 0.1694 - val_mrcnn_mask_loss: 0.2231\n",
      "Epoch 8/16\n",
      "666/666 [==============================] - 1529s 2s/step - loss: 0.6629 - rpn_class_loss: 0.0100 - rpn_bbox_loss: 0.2241 - mrcnn_class_loss: 0.0244 - mrcnn_bbox_loss: 0.1651 - mrcnn_mask_loss: 0.2392 - val_loss: 0.6715 - val_rpn_class_loss: 0.0082 - val_rpn_bbox_loss: 0.2203 - val_mrcnn_class_loss: 0.0215 - val_mrcnn_bbox_loss: 0.1696 - val_mrcnn_mask_loss: 0.2519\n",
      "Epoch 9/16\n",
      "666/666 [==============================] - 1516s 2s/step - loss: 0.6806 - rpn_class_loss: 0.0094 - rpn_bbox_loss: 0.2313 - mrcnn_class_loss: 0.0249 - mrcnn_bbox_loss: 0.1718 - mrcnn_mask_loss: 0.2431 - val_loss: 0.5962 - val_rpn_class_loss: 0.0078 - val_rpn_bbox_loss: 0.1672 - val_mrcnn_class_loss: 0.0224 - val_mrcnn_bbox_loss: 0.1624 - val_mrcnn_mask_loss: 0.2364\n",
      "Epoch 10/16\n",
      "666/666 [==============================] - 1544s 2s/step - loss: 0.6642 - rpn_class_loss: 0.0097 - rpn_bbox_loss: 0.2138 - mrcnn_class_loss: 0.0251 - mrcnn_bbox_loss: 0.1724 - mrcnn_mask_loss: 0.2431 - val_loss: 0.6085 - val_rpn_class_loss: 0.0098 - val_rpn_bbox_loss: 0.1970 - val_mrcnn_class_loss: 0.0216 - val_mrcnn_bbox_loss: 0.1480 - val_mrcnn_mask_loss: 0.2320\n",
      "Epoch 11/16\n",
      "666/666 [==============================] - 1560s 2s/step - loss: 0.6580 - rpn_class_loss: 0.0092 - rpn_bbox_loss: 0.2148 - mrcnn_class_loss: 0.0248 - mrcnn_bbox_loss: 0.1657 - mrcnn_mask_loss: 0.2434 - val_loss: 0.7326 - val_rpn_class_loss: 0.0112 - val_rpn_bbox_loss: 0.2314 - val_mrcnn_class_loss: 0.0278 - val_mrcnn_bbox_loss: 0.2026 - val_mrcnn_mask_loss: 0.2595\n",
      "Epoch 12/16\n",
      "666/666 [==============================] - 1573s 2s/step - loss: 0.6555 - rpn_class_loss: 0.0101 - rpn_bbox_loss: 0.2121 - mrcnn_class_loss: 0.0271 - mrcnn_bbox_loss: 0.1653 - mrcnn_mask_loss: 0.2409 - val_loss: 0.7105 - val_rpn_class_loss: 0.0123 - val_rpn_bbox_loss: 0.2628 - val_mrcnn_class_loss: 0.0344 - val_mrcnn_bbox_loss: 0.1655 - val_mrcnn_mask_loss: 0.2355\n",
      "Epoch 13/16\n",
      "666/666 [==============================] - 1569s 2s/step - loss: 0.6444 - rpn_class_loss: 0.0100 - rpn_bbox_loss: 0.2095 - mrcnn_class_loss: 0.0252 - mrcnn_bbox_loss: 0.1640 - mrcnn_mask_loss: 0.2356 - val_loss: 0.7248 - val_rpn_class_loss: 0.0101 - val_rpn_bbox_loss: 0.2517 - val_mrcnn_class_loss: 0.0271 - val_mrcnn_bbox_loss: 0.1889 - val_mrcnn_mask_loss: 0.2469\n",
      "Epoch 14/16\n",
      "666/666 [==============================] - 1539s 2s/step - loss: 0.6638 - rpn_class_loss: 0.0100 - rpn_bbox_loss: 0.2193 - mrcnn_class_loss: 0.0270 - mrcnn_bbox_loss: 0.1655 - mrcnn_mask_loss: 0.2419 - val_loss: 0.6511 - val_rpn_class_loss: 0.0080 - val_rpn_bbox_loss: 0.1889 - val_mrcnn_class_loss: 0.0258 - val_mrcnn_bbox_loss: 0.1800 - val_mrcnn_mask_loss: 0.2483\n",
      "Epoch 15/16\n",
      "666/666 [==============================] - 1538s 2s/step - loss: 0.6619 - rpn_class_loss: 0.0093 - rpn_bbox_loss: 0.2210 - mrcnn_class_loss: 0.0234 - mrcnn_bbox_loss: 0.1641 - mrcnn_mask_loss: 0.2439 - val_loss: 0.6489 - val_rpn_class_loss: 0.0080 - val_rpn_bbox_loss: 0.2184 - val_mrcnn_class_loss: 0.0230 - val_mrcnn_bbox_loss: 0.1609 - val_mrcnn_mask_loss: 0.2385\n",
      "Epoch 16/16\n",
      "666/666 [==============================] - 1538s 2s/step - loss: 0.6601 - rpn_class_loss: 0.0098 - rpn_bbox_loss: 0.2172 - mrcnn_class_loss: 0.0242 - mrcnn_bbox_loss: 0.1681 - mrcnn_mask_loss: 0.2408 - val_loss: 0.5992 - val_rpn_class_loss: 0.0089 - val_rpn_bbox_loss: 0.1790 - val_mrcnn_class_loss: 0.0242 - val_mrcnn_bbox_loss: 0.1520 - val_mrcnn_mask_loss: 0.2351\n",
      "\n",
      "Starting at epoch 16. LR=1e-06\n",
      "\n",
      "Checkpoint Path: H:\\ObjectDetection\\AiRobot_WAD_Video_Segmentation\\logs\\mask_rcnn\\adriving20181030T0828\\mask_rcnn_adriving_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/32\n",
      "666/666 [==============================] - 1662s 2s/step - loss: 0.6599 - rpn_class_loss: 0.0104 - rpn_bbox_loss: 0.2115 - mrcnn_class_loss: 0.0279 - mrcnn_bbox_loss: 0.1687 - mrcnn_mask_loss: 0.2413 - val_loss: 0.6559 - val_rpn_class_loss: 0.0108 - val_rpn_bbox_loss: 0.2226 - val_mrcnn_class_loss: 0.0259 - val_mrcnn_bbox_loss: 0.1581 - val_mrcnn_mask_loss: 0.2384\n",
      "Epoch 18/32\n",
      "666/666 [==============================] - 1664s 2s/step - loss: 0.6656 - rpn_class_loss: 0.0096 - rpn_bbox_loss: 0.2309 - mrcnn_class_loss: 0.0264 - mrcnn_bbox_loss: 0.1639 - mrcnn_mask_loss: 0.2347 - val_loss: 0.6060 - val_rpn_class_loss: 0.0078 - val_rpn_bbox_loss: 0.1842 - val_mrcnn_class_loss: 0.0266 - val_mrcnn_bbox_loss: 0.1526 - val_mrcnn_mask_loss: 0.2347\n",
      "Epoch 19/32\n",
      "666/666 [==============================] - 1666s 3s/step - loss: 0.6797 - rpn_class_loss: 0.0102 - rpn_bbox_loss: 0.2296 - mrcnn_class_loss: 0.0269 - mrcnn_bbox_loss: 0.1710 - mrcnn_mask_loss: 0.2419 - val_loss: 0.6432 - val_rpn_class_loss: 0.0081 - val_rpn_bbox_loss: 0.1992 - val_mrcnn_class_loss: 0.0288 - val_mrcnn_bbox_loss: 0.1741 - val_mrcnn_mask_loss: 0.2328\n",
      "Epoch 20/32\n",
      "666/666 [==============================] - 1630s 2s/step - loss: 0.6588 - rpn_class_loss: 0.0093 - rpn_bbox_loss: 0.2272 - mrcnn_class_loss: 0.0242 - mrcnn_bbox_loss: 0.1598 - mrcnn_mask_loss: 0.2383 - val_loss: 0.7348 - val_rpn_class_loss: 0.0127 - val_rpn_bbox_loss: 0.2532 - val_mrcnn_class_loss: 0.0307 - val_mrcnn_bbox_loss: 0.1834 - val_mrcnn_mask_loss: 0.2548\n",
      "Epoch 21/32\n",
      "666/666 [==============================] - 1623s 2s/step - loss: 0.6665 - rpn_class_loss: 0.0096 - rpn_bbox_loss: 0.2231 - mrcnn_class_loss: 0.0243 - mrcnn_bbox_loss: 0.1676 - mrcnn_mask_loss: 0.2419 - val_loss: 0.5884 - val_rpn_class_loss: 0.0106 - val_rpn_bbox_loss: 0.1902 - val_mrcnn_class_loss: 0.0219 - val_mrcnn_bbox_loss: 0.1508 - val_mrcnn_mask_loss: 0.2150\n",
      "Epoch 22/32\n",
      "666/666 [==============================] - 1616s 2s/step - loss: 0.6674 - rpn_class_loss: 0.0100 - rpn_bbox_loss: 0.2259 - mrcnn_class_loss: 0.0256 - mrcnn_bbox_loss: 0.1655 - mrcnn_mask_loss: 0.2403 - val_loss: 0.6622 - val_rpn_class_loss: 0.0075 - val_rpn_bbox_loss: 0.2701 - val_mrcnn_class_loss: 0.0141 - val_mrcnn_bbox_loss: 0.1531 - val_mrcnn_mask_loss: 0.2172\n",
      "Epoch 23/32\n",
      "666/666 [==============================] - 1600s 2s/step - loss: 0.6555 - rpn_class_loss: 0.0098 - rpn_bbox_loss: 0.2102 - mrcnn_class_loss: 0.0251 - mrcnn_bbox_loss: 0.1692 - mrcnn_mask_loss: 0.2412 - val_loss: 0.7579 - val_rpn_class_loss: 0.0095 - val_rpn_bbox_loss: 0.2467 - val_mrcnn_class_loss: 0.0294 - val_mrcnn_bbox_loss: 0.2131 - val_mrcnn_mask_loss: 0.2591\n",
      "Epoch 24/32\n",
      "666/666 [==============================] - 1612s 2s/step - loss: 0.6959 - rpn_class_loss: 0.0102 - rpn_bbox_loss: 0.2393 - mrcnn_class_loss: 0.0259 - mrcnn_bbox_loss: 0.1731 - mrcnn_mask_loss: 0.2474 - val_loss: 0.6901 - val_rpn_class_loss: 0.0098 - val_rpn_bbox_loss: 0.2393 - val_mrcnn_class_loss: 0.0275 - val_mrcnn_bbox_loss: 0.1724 - val_mrcnn_mask_loss: 0.2410\n",
      "Epoch 25/32\n",
      "666/666 [==============================] - 1635s 2s/step - loss: 0.6854 - rpn_class_loss: 0.0106 - rpn_bbox_loss: 0.2317 - mrcnn_class_loss: 0.0272 - mrcnn_bbox_loss: 0.1696 - mrcnn_mask_loss: 0.2462 - val_loss: 0.6791 - val_rpn_class_loss: 0.0112 - val_rpn_bbox_loss: 0.2198 - val_mrcnn_class_loss: 0.0310 - val_mrcnn_bbox_loss: 0.1710 - val_mrcnn_mask_loss: 0.2461\n",
      "Epoch 26/32\n",
      "666/666 [==============================] - 1656s 2s/step - loss: 0.6733 - rpn_class_loss: 0.0102 - rpn_bbox_loss: 0.2369 - mrcnn_class_loss: 0.0259 - mrcnn_bbox_loss: 0.1629 - mrcnn_mask_loss: 0.2374 - val_loss: 0.6472 - val_rpn_class_loss: 0.0096 - val_rpn_bbox_loss: 0.1816 - val_mrcnn_class_loss: 0.0235 - val_mrcnn_bbox_loss: 0.1708 - val_mrcnn_mask_loss: 0.2617\n",
      "Epoch 27/32\n",
      "666/666 [==============================] - 1657s 2s/step - loss: 0.6779 - rpn_class_loss: 0.0100 - rpn_bbox_loss: 0.2362 - mrcnn_class_loss: 0.0232 - mrcnn_bbox_loss: 0.1681 - mrcnn_mask_loss: 0.2404 - val_loss: 0.6919 - val_rpn_class_loss: 0.0112 - val_rpn_bbox_loss: 0.2015 - val_mrcnn_class_loss: 0.0280 - val_mrcnn_bbox_loss: 0.1819 - val_mrcnn_mask_loss: 0.2691\n",
      "Epoch 28/32\n",
      "666/666 [==============================] - 1642s 2s/step - loss: 0.6710 - rpn_class_loss: 0.0101 - rpn_bbox_loss: 0.2195 - mrcnn_class_loss: 0.0271 - mrcnn_bbox_loss: 0.1694 - mrcnn_mask_loss: 0.2448 - val_loss: 0.6447 - val_rpn_class_loss: 0.0113 - val_rpn_bbox_loss: 0.2010 - val_mrcnn_class_loss: 0.0275 - val_mrcnn_bbox_loss: 0.1681 - val_mrcnn_mask_loss: 0.2366\n",
      "Epoch 29/32\n",
      "666/666 [==============================] - 1639s 2s/step - loss: 0.6562 - rpn_class_loss: 0.0096 - rpn_bbox_loss: 0.2215 - mrcnn_class_loss: 0.0252 - mrcnn_bbox_loss: 0.1629 - mrcnn_mask_loss: 0.2370 - val_loss: 0.6993 - val_rpn_class_loss: 0.0102 - val_rpn_bbox_loss: 0.2473 - val_mrcnn_class_loss: 0.0244 - val_mrcnn_bbox_loss: 0.1704 - val_mrcnn_mask_loss: 0.2469\n",
      "Epoch 30/32\n",
      "666/666 [==============================] - 1637s 2s/step - loss: 0.6906 - rpn_class_loss: 0.0101 - rpn_bbox_loss: 0.2426 - mrcnn_class_loss: 0.0260 - mrcnn_bbox_loss: 0.1688 - mrcnn_mask_loss: 0.2430 - val_loss: 0.6372 - val_rpn_class_loss: 0.0100 - val_rpn_bbox_loss: 0.2076 - val_mrcnn_class_loss: 0.0278 - val_mrcnn_bbox_loss: 0.1576 - val_mrcnn_mask_loss: 0.2342\n",
      "Epoch 31/32\n",
      "666/666 [==============================] - 1643s 2s/step - loss: 0.6644 - rpn_class_loss: 0.0106 - rpn_bbox_loss: 0.2137 - mrcnn_class_loss: 0.0256 - mrcnn_bbox_loss: 0.1708 - mrcnn_mask_loss: 0.2435 - val_loss: 0.7402 - val_rpn_class_loss: 0.0094 - val_rpn_bbox_loss: 0.2507 - val_mrcnn_class_loss: 0.0305 - val_mrcnn_bbox_loss: 0.1865 - val_mrcnn_mask_loss: 0.2629\n",
      "Epoch 32/32\n",
      "666/666 [==============================] - 1666s 3s/step - loss: 0.6566 - rpn_class_loss: 0.0099 - rpn_bbox_loss: 0.2158 - mrcnn_class_loss: 0.0257 - mrcnn_bbox_loss: 0.1638 - mrcnn_mask_loss: 0.2413 - val_loss: 0.6541 - val_rpn_class_loss: 0.0084 - val_rpn_bbox_loss: 0.2078 - val_mrcnn_class_loss: 0.0223 - val_mrcnn_bbox_loss: 0.1699 - val_mrcnn_mask_loss: 0.2457\n",
      "\n",
      "Starting at epoch 32. LR=1e-07\n",
      "\n",
      "Checkpoint Path: H:\\ObjectDetection\\AiRobot_WAD_Video_Segmentation\\logs\\mask_rcnn\\adriving20181030T0828\\mask_rcnn_adriving_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/48\n",
      "666/666 [==============================] - 1679s 3s/step - loss: 0.6541 - rpn_class_loss: 0.0102 - rpn_bbox_loss: 0.2048 - mrcnn_class_loss: 0.0265 - mrcnn_bbox_loss: 0.1686 - mrcnn_mask_loss: 0.2440 - val_loss: 0.6409 - val_rpn_class_loss: 0.0102 - val_rpn_bbox_loss: 0.2295 - val_mrcnn_class_loss: 0.0231 - val_mrcnn_bbox_loss: 0.1559 - val_mrcnn_mask_loss: 0.2221\n",
      "Epoch 34/48\n",
      "666/666 [==============================] - 1670s 3s/step - loss: 0.6807 - rpn_class_loss: 0.0105 - rpn_bbox_loss: 0.2268 - mrcnn_class_loss: 0.0255 - mrcnn_bbox_loss: 0.1710 - mrcnn_mask_loss: 0.2468 - val_loss: 0.6400 - val_rpn_class_loss: 0.0087 - val_rpn_bbox_loss: 0.2361 - val_mrcnn_class_loss: 0.0220 - val_mrcnn_bbox_loss: 0.1483 - val_mrcnn_mask_loss: 0.2250\n",
      "Epoch 35/48\n",
      "666/666 [==============================] - 1670s 3s/step - loss: 0.6826 - rpn_class_loss: 0.0100 - rpn_bbox_loss: 0.2326 - mrcnn_class_loss: 0.0254 - mrcnn_bbox_loss: 0.1712 - mrcnn_mask_loss: 0.2434 - val_loss: 0.7530 - val_rpn_class_loss: 0.0117 - val_rpn_bbox_loss: 0.2643 - val_mrcnn_class_loss: 0.0348 - val_mrcnn_bbox_loss: 0.1850 - val_mrcnn_mask_loss: 0.2572\n",
      "Epoch 36/48\n",
      "666/666 [==============================] - 1664s 2s/step - loss: 0.6660 - rpn_class_loss: 0.0104 - rpn_bbox_loss: 0.2101 - mrcnn_class_loss: 0.0266 - mrcnn_bbox_loss: 0.1722 - mrcnn_mask_loss: 0.2466 - val_loss: 0.6353 - val_rpn_class_loss: 0.0115 - val_rpn_bbox_loss: 0.2099 - val_mrcnn_class_loss: 0.0200 - val_mrcnn_bbox_loss: 0.1579 - val_mrcnn_mask_loss: 0.2360\n",
      "Epoch 37/48\n",
      "666/666 [==============================] - 1684s 3s/step - loss: 0.6951 - rpn_class_loss: 0.0107 - rpn_bbox_loss: 0.2420 - mrcnn_class_loss: 0.0273 - mrcnn_bbox_loss: 0.1689 - mrcnn_mask_loss: 0.2460 - val_loss: 0.6417 - val_rpn_class_loss: 0.0103 - val_rpn_bbox_loss: 0.2163 - val_mrcnn_class_loss: 0.0301 - val_mrcnn_bbox_loss: 0.1505 - val_mrcnn_mask_loss: 0.2345\n",
      "Epoch 38/48\n",
      "666/666 [==============================] - 1665s 3s/step - loss: 0.6612 - rpn_class_loss: 0.0099 - rpn_bbox_loss: 0.2168 - mrcnn_class_loss: 0.0250 - mrcnn_bbox_loss: 0.1674 - mrcnn_mask_loss: 0.2421 - val_loss: 0.7192 - val_rpn_class_loss: 0.0107 - val_rpn_bbox_loss: 0.2476 - val_mrcnn_class_loss: 0.0312 - val_mrcnn_bbox_loss: 0.1823 - val_mrcnn_mask_loss: 0.2474\n",
      "Epoch 39/48\n",
      "666/666 [==============================] - 1678s 3s/step - loss: 0.6711 - rpn_class_loss: 0.0105 - rpn_bbox_loss: 0.2148 - mrcnn_class_loss: 0.0292 - mrcnn_bbox_loss: 0.1706 - mrcnn_mask_loss: 0.2459 - val_loss: 0.7600 - val_rpn_class_loss: 0.0095 - val_rpn_bbox_loss: 0.2898 - val_mrcnn_class_loss: 0.0196 - val_mrcnn_bbox_loss: 0.1775 - val_mrcnn_mask_loss: 0.2636\n",
      "Epoch 40/48\n",
      "666/666 [==============================] - 1658s 2s/step - loss: 0.6640 - rpn_class_loss: 0.0100 - rpn_bbox_loss: 0.2310 - mrcnn_class_loss: 0.0242 - mrcnn_bbox_loss: 0.1628 - mrcnn_mask_loss: 0.2360 - val_loss: 0.6615 - val_rpn_class_loss: 0.0098 - val_rpn_bbox_loss: 0.2349 - val_mrcnn_class_loss: 0.0185 - val_mrcnn_bbox_loss: 0.1708 - val_mrcnn_mask_loss: 0.2275\n",
      "Epoch 41/48\n",
      "666/666 [==============================] - 1677s 3s/step - loss: 0.6539 - rpn_class_loss: 0.0107 - rpn_bbox_loss: 0.2099 - mrcnn_class_loss: 0.0275 - mrcnn_bbox_loss: 0.1624 - mrcnn_mask_loss: 0.2434 - val_loss: 0.6395 - val_rpn_class_loss: 0.0095 - val_rpn_bbox_loss: 0.1867 - val_mrcnn_class_loss: 0.0263 - val_mrcnn_bbox_loss: 0.1666 - val_mrcnn_mask_loss: 0.2503\n",
      "Epoch 42/48\n",
      "666/666 [==============================] - 1658s 2s/step - loss: 0.6766 - rpn_class_loss: 0.0103 - rpn_bbox_loss: 0.2232 - mrcnn_class_loss: 0.0261 - mrcnn_bbox_loss: 0.1722 - mrcnn_mask_loss: 0.2448 - val_loss: 0.6470 - val_rpn_class_loss: 0.0098 - val_rpn_bbox_loss: 0.2123 - val_mrcnn_class_loss: 0.0223 - val_mrcnn_bbox_loss: 0.1683 - val_mrcnn_mask_loss: 0.2343\n",
      "Epoch 43/48\n",
      "666/666 [==============================] - 1671s 3s/step - loss: 0.6924 - rpn_class_loss: 0.0104 - rpn_bbox_loss: 0.2560 - mrcnn_class_loss: 0.0253 - mrcnn_bbox_loss: 0.1645 - mrcnn_mask_loss: 0.2361 - val_loss: 0.7562 - val_rpn_class_loss: 0.0098 - val_rpn_bbox_loss: 0.2733 - val_mrcnn_class_loss: 0.0290 - val_mrcnn_bbox_loss: 0.1821 - val_mrcnn_mask_loss: 0.2619\n",
      "Epoch 44/48\n",
      "666/666 [==============================] - 1665s 3s/step - loss: 0.6551 - rpn_class_loss: 0.0095 - rpn_bbox_loss: 0.2171 - mrcnn_class_loss: 0.0255 - mrcnn_bbox_loss: 0.1662 - mrcnn_mask_loss: 0.2367 - val_loss: 0.6495 - val_rpn_class_loss: 0.0085 - val_rpn_bbox_loss: 0.2159 - val_mrcnn_class_loss: 0.0217 - val_mrcnn_bbox_loss: 0.1697 - val_mrcnn_mask_loss: 0.2336\n",
      "Epoch 45/48\n",
      "666/666 [==============================] - 1655s 2s/step - loss: 0.6649 - rpn_class_loss: 0.0098 - rpn_bbox_loss: 0.2253 - mrcnn_class_loss: 0.0247 - mrcnn_bbox_loss: 0.1661 - mrcnn_mask_loss: 0.2389 - val_loss: 0.6977 - val_rpn_class_loss: 0.0105 - val_rpn_bbox_loss: 0.2697 - val_mrcnn_class_loss: 0.0254 - val_mrcnn_bbox_loss: 0.1610 - val_mrcnn_mask_loss: 0.2311\n",
      "Epoch 46/48\n",
      "666/666 [==============================] - 1642s 2s/step - loss: 0.6946 - rpn_class_loss: 0.0108 - rpn_bbox_loss: 0.2320 - mrcnn_class_loss: 0.0276 - mrcnn_bbox_loss: 0.1764 - mrcnn_mask_loss: 0.2478 - val_loss: 0.7191 - val_rpn_class_loss: 0.0095 - val_rpn_bbox_loss: 0.2431 - val_mrcnn_class_loss: 0.0298 - val_mrcnn_bbox_loss: 0.1799 - val_mrcnn_mask_loss: 0.2567\n",
      "Epoch 47/48\n",
      "666/666 [==============================] - 1647s 2s/step - loss: 0.6777 - rpn_class_loss: 0.0097 - rpn_bbox_loss: 0.2283 - mrcnn_class_loss: 0.0263 - mrcnn_bbox_loss: 0.1702 - mrcnn_mask_loss: 0.2431 - val_loss: 0.6056 - val_rpn_class_loss: 0.0091 - val_rpn_bbox_loss: 0.1951 - val_mrcnn_class_loss: 0.0225 - val_mrcnn_bbox_loss: 0.1531 - val_mrcnn_mask_loss: 0.2258\n",
      "Epoch 48/48\n",
      "666/666 [==============================] - 1646s 2s/step - loss: 0.6709 - rpn_class_loss: 0.0104 - rpn_bbox_loss: 0.2206 - mrcnn_class_loss: 0.0255 - mrcnn_bbox_loss: 0.1717 - mrcnn_mask_loss: 0.2427 - val_loss: 0.6569 - val_rpn_class_loss: 0.0105 - val_rpn_bbox_loss: 0.2239 - val_mrcnn_class_loss: 0.0231 - val_mrcnn_bbox_loss: 0.1664 - val_mrcnn_mask_loss: 0.2330\n",
      "\n",
      "Starting at epoch 48. LR=1e-07\n",
      "\n",
      "Checkpoint Path: H:\\ObjectDetection\\AiRobot_WAD_Video_Segmentation\\logs\\mask_rcnn\\adriving20181030T0828\\mask_rcnn_adriving_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/64\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "#  Training\n",
    "############################################################\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    config = AdrivingConfig()\n",
    "    config.display()\n",
    "    DEVICE = \"/gpu:0\"  # /cpu:0 or /gpu:0\n",
    "\n",
    "    model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                              model_dir=os.path.join(DEFAULT_LOGS_DIR, 'mask_rcnn'))\n",
    "    \n",
    "    PRETRAIN_WEIGHTS_PATH = os.path.join(ROOT_DIR, setting['MODEL_CHECKPOINT_DIR'], 'mask_rcnn_adriving_0026.h5')\n",
    "\n",
    "    \n",
    "    weights_path = PRETRAIN_WEIGHTS_PATH\n",
    "    model.load_weights(weights_path, by_name=True)\n",
    "    \n",
    "    data_dir = Path(os.path.join(ROOT_DIR, setting['TEST_DATA_CLEAN_PATH'], 'train_val'))\n",
    "    train(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
